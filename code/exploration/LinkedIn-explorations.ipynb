{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "339c1411f5b1a796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyspark pyarrow pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55936eb5ea5f5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "try:\n",
    "    spark\n",
    "except NameError:\n",
    "    print(\"üîÑ No existing SparkSession found. Creating a new one...\")\n",
    "    spark = SparkSession.builder.appName(\"Tu App\").master(\"local[*]\").getOrCreate()\n",
    "    print(\"‚úÖ SparkSession created successfully.\")\n",
    "else:\n",
    "    if spark._jsparkSession is None:\n",
    "        print(\"‚ö†Ô∏è Existing SparkSession is not active. Recreating it...\")\n",
    "        spark = SparkSession.builder.appName(\"Tu App\").master(\"local[*]\").getOrCreate()\n",
    "        print(\"‚úÖ SparkSession re-created successfully.\")\n",
    "    else:\n",
    "        print(\"‚úÖ SparkSession is already active.\")\n",
    "\n",
    "print(f\"üî• Spark is running ‚Äî version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fc1758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d6fd4fe17e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_df = spark.read.csv(base_path + \"Skills.csv\", header=True, inferSchema=True)\n",
    "print(\"Schema: \")\n",
    "skills_df.printSchema()\n",
    "count_skills = skills_df.count()\n",
    "print(f\"Number of skills: {count_skills}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "skills_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = spark.read.csv(base_path + \"Profile.csv\", header=True, inferSchema=True)\n",
    "print(\"Schema: \")\n",
    "profile_df.printSchema()\n",
    "count_profile = profile_df.count()\n",
    "print(f\"Number of profile: {count_profile}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "profile_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4105e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions_df = spark.read.csv(\n",
    "    base_path + \"Positions.csv\", header=True, inferSchema=True\n",
    ")\n",
    "print(\"Schema: \")\n",
    "positions_df.printSchema()\n",
    "count_positions = positions_df.count()\n",
    "print(f\"Number of positions: {count_positions}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "positions_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10255e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_df = spark.read.csv(\n",
    "    base_path + \"Languages.csv\", header=True, inferSchema=True\n",
    ")\n",
    "print(\"Schema: \")\n",
    "languages_df.printSchema()\n",
    "count_languages = languages_df.count()\n",
    "print(f\"Number of languages: {count_languages}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "languages_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8dd34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "invitations_df = spark.read.csv(\n",
    "    base_path + \"Invitations.csv\", header=True, inferSchema=True\n",
    ")\n",
    "print(\"Schema: \")\n",
    "invitations_df.printSchema()\n",
    "count_invitations = invitations_df.count()\n",
    "print(f\"Number of invitations: {count_invitations}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "invitations_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52487824",
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df = spark.read.csv(\n",
    "    base_path + \"Education.csv\", header=True, inferSchema=True\n",
    ")\n",
    "print(\"Schema: \")\n",
    "education_df.printSchema()\n",
    "count_education = education_df.count()\n",
    "print(f\"Number of education: {count_education}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "education_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_df = spark.read.csv(\n",
    "    base_path + \"Connections.csv\", header=True, inferSchema=True\n",
    ")\n",
    "print(\"Schema: \")\n",
    "connections_df.printSchema()\n",
    "count_connections = connections_df.count()\n",
    "print(f\"Number of connections: {count_connections}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "connections_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_followers_df = spark.read.csv(\n",
    "    base_path + \"Company Follows.csv\", header=True, inferSchema=True\n",
    ")\n",
    "print(\"Schema: \")\n",
    "company_followers_df.printSchema()\n",
    "count_company_followers = company_followers_df.count()\n",
    "print(f\"Number of company followers: {count_company_followers}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "company_followers_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3cc953",
   "metadata": {},
   "outputs": [],
   "source": [
    "certifications_df = spark.read.csv(\n",
    "    base_path + \"Certifications.csv\", header=True, inferSchema=True\n",
    ")\n",
    "print(\"Schema: \")\n",
    "certifications_df.printSchema()\n",
    "count_certifications = certifications_df.count()\n",
    "print(f\"Number of certifications: {count_certifications}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "certifications_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1173fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_jobs_df = spark.read.csv(\n",
    "    base_path + \"Saved Jobs.csv\", header=True, inferSchema=True\n",
    ")\n",
    "print(\"Schema: \")\n",
    "saved_jobs_df.printSchema()\n",
    "count_saved_jobs = saved_jobs_df.count()\n",
    "print(f\"Number of saved jobs: {count_saved_jobs}\")\n",
    "print(\"\\nFirst rows: \")\n",
    "saved_jobs_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa19e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark351",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
